# ğŸ“„ RAG Document Assistant (Local, Streaming, Scalable)

A **production-ready Retrieval-Augmented Generation (RAG) system** that allows users to upload documents (PDF / CSV / Excel) and ask questions with **live streaming AI responses**, running **entirely locally** using Ollama.

This project demonstrates **real-world AI backend engineering**, not a toy example.

---

## ğŸš€ Features

- ğŸ“¤ Upload documents (PDF, CSV, Excel)
- ğŸ§  Automatic document parsing & chunking
- ğŸ”¢ Vector embeddings using PostgreSQL + pgvector
- ğŸ” Semantic search over document content
- ğŸ’¬ Streaming answers (token-by-token)
- ğŸ§‘ Multi-user safe (user-scoped data)
- ğŸ  Fully local setup (no OpenAI required)
- âš¡ FastAPI + async PostgreSQL backend
- ğŸ¨ Streamlit frontend UI

---

## ğŸ§± Architecture Overview

User (Streamlit UI)
    â†“
Upload Document
    â†“
FastAPI Backend
    â”œâ”€ Parse document
    â”œâ”€ Chunk text
    â”œâ”€ Generate embeddings (Ollama)
    â”œâ”€ Store in PostgreSQL (pgvector)
    â†“
Ask Question
    â†“
Vector similarity search
    â†“
Prompt construction
    â†“
Streaming LLM answer (Ollama)

---

## ğŸ› ï¸ Tech Stack

### Backend
- FastAPI
- PostgreSQL + pgvector
- asyncpg

### AI / NLP
- Ollama
  - qwen2:1.5b (LLM)
  - nomic-embed-text (Embeddings)

### Frontend
- Streamlit
- Live streaming UI

---

## âš™ï¸ Setup Instructions

### PostgreSQL + pgvector
Install PostgreSQL and pgvector, then enable the extension:

CREATE EXTENSION vector;

### Ollama
Install and pull models:

ollama pull qwen2:1.5b
ollama pull nomic-embed-text

### Backend
Run:
uvicorn app.main:app --reload

### Frontend
Run:
streamlit run streamlit.py

---

## ğŸ‘¨â€ğŸ’» Author

Shubham Singh



## System Architecture Diagram

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Streamlit   â”‚
â”‚   Frontend   â”‚
â”‚ (File Upload â”‚
â”‚  + Questions)â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚ HTTP (REST)
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚      FastAPI         â”‚
â”‚   Application API    â”‚
â”‚----------------------â”‚
â”‚ /documents/upload    â”‚
â”‚ /documents/embed     â”‚
â”‚ /ask/stream          â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚ async DB / IO
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚       PostgreSQL             â”‚
â”‚------------------------------â”‚
â”‚ documents table              â”‚
â”‚ embeddings table (pgvector)  â”‚
â”‚ vector indexes (future)      â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚ similarity search
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Retrieval Layer         â”‚
â”‚---------------------------â”‚
â”‚ cosine similarity search  â”‚
â”‚ top-K chunk selection     â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚ context chunks
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Prompt Builder          â”‚
â”‚---------------------------â”‚
â”‚ strict grounding rules    â”‚
â”‚ summary / numeric logic   â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚ prompt
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   LLM (Ollama)            â”‚
â”‚---------------------------â”‚
â”‚ local inference           â”‚
â”‚ token streaming           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚ streamed tokens
           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Streamlit UI        â”‚
â”‚ (Live response)     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
